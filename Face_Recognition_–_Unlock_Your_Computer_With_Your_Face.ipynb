{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JuPUPXqGq4s"
   },
   "source": [
    "## Face Recognition – Unlock Your Computer With Your Face!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIclV_ySGq4w"
   },
   "source": [
    "\n",
    "### Step 1 - Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cjKXBmcSGq4x",
    "outputId": "cf114529-f2f3-48dc-c542-3e4a289994b6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-9-d276eaa69c54>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './datasetd/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bmJIThPGq40"
   },
   "source": [
    "### Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FjHkTVyGq40"
   },
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RIEg4yxiGq41",
    "outputId": "cbba75a1-7e01-4add-a100-360d425628a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = './datasetd/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "vimal_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "vimal_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkDytCefGq42"
   },
   "source": [
    "### Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8UPzCyNRGq42",
    "outputId": "3f2359a1-39ca-4345-a819-2640bb58961e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-11-6561706762b5>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws started\n",
      "Whatsapp Message sent Successfully!!\n",
      "Mail Sent Successfully..!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pywhatkit\n",
    "import smtplib\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = vimal_model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 80:\n",
    "                \n",
    "            cv2.putText(image, \"Hi Hardik\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            \n",
    "            awscli()\n",
    "            #time.sleep(20)\n",
    "            whatsapp()\n",
    "            #time.sleep(20)\n",
    "            send_mail()\n",
    "            #time.sleep(40)\n",
    "            \n",
    "            \n",
    "            #os.system(\"chrome https://www.google.com/search?q=vimal+daga\")\n",
    "            #os.system(\"wmplayer   c:\\lw.mp3\")\n",
    "            \n",
    "            #os.system(\"r:\")\n",
    "            #os.system(\"R:\\Family\\MLOPS\\CV\\Task-6\")\n",
    "            #pywhatkit.sendwhatmsg_instantly(phone_no=\"+918306903226\", message=\"Message sent by Face Recognition\")\n",
    "            #print(\"Whatsapp Message sent Successfully!!\") \n",
    "            #pywhatkit.send_mail(\"singhalhardik03@gmail.com\",\n",
    "            #                     \"Agarwal@98\",\n",
    "            #                     \"Face Recoginition\",\n",
    "            #                     \"This is face of Hardik Singhal\",\n",
    "            #                     \"singhalhardik03@gmail.com\")\n",
    "            \n",
    "            #aws instance launch\n",
    "#             os.system(\"aws ec2 run-instances --image-id ami-0ad704c126371a549 --count 1 --instance-type t2.micro --key-name scyt --security-group-ids sg-0bef56f78c13e1f25 --subnet-id subnet-2212fb49 > aws_instance_id.txt\")\n",
    "#             print(\"Instance Created\")\n",
    "#             instance_ID = open(\"aws_instance_id.txt\", \"r\").read().split(\",\")[3].split(\":\")[1].split('\"')[1]\n",
    "#             os.system(\"aws ec2 create-volume --size 5 --availability-zone ap-south-1a > volume.txt\")\n",
    "#             time.sleep(20)\n",
    "#             print(\"Volume of 5gb Created\")\n",
    "#             vol_ID = open(\"volume.txt\", \"r\").read().split(\",\")[6].split(\":\")[1].split('\"')[1]\n",
    "#             os.system(\"aws ec2 attach-volume --volume-id \" + vol_ID +  \" --instance-id \" + instance_ID + \" --device /dev/sdf\")\n",
    "#             print(\"Volume attached\")  \n",
    "            break\n",
    "         \n",
    "        else:\n",
    "            \n",
    "            cv2.putText(image, \"I dont know, who r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(\n",
    "            image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     \n",
    "\n",
    "def send_mail():\n",
    "    smtpObj = smtplib.SMTP('smtp.gmail.com',587)\n",
    "    smtpObj.ehlo()\n",
    "    smtpObj.starttls()\n",
    "    smtpObj.login(\"has098mnb@gmail.com\", \"GMAILTEST\")\n",
    "    smtpObj.sendmail(\"singhalhardik003@gmail.com\", \"iamhardiksinghal@gmail.com\", 'Subject: Hello Hardik! \\nYou have successfully sent a mail I Recognize Hardik\\'s Face Just Now ')\n",
    "    smtpObj.quit()\n",
    "    print('Mail Sent Successfully..!!')\n",
    "    \n",
    "def whatsapp():\n",
    "    pywhatkit.sendwhatmsg_instantly(\"+918306903226\", \"Hello!!, This is from Face Recognition Model\")\n",
    "    print(\"Whatsapp Message sent Successfully!!\")\n",
    "    \n",
    "\n",
    "def awscli():\n",
    "    print('aws started')\n",
    "    a=os.system(\"aws ec2 run-instances --image-id ami-06a0b4e3b7eb7a300 --count 1 --instance-type t2.micro --key-name doc-web --subnet-id subnet-aa020bc2  --tag-specifications  ResourceType=instance,Tags=[{Key=Name,Value=testos1os}]\")\n",
    "    if a == 0:\n",
    "        print(\"Success : AWS Instance Launched\")\n",
    "    b = os.system(\"aws ec2 create-volume --volume-type gp2 --size 5 --subnet-id subnet-aa020bc2  --tag-specifications  ResourceType=volume,Tags=[{Key=Name,Value=testos1}]\")\n",
    "    if b == 0:\n",
    "        print(\"Success :  AWS Volume Created\")\n",
    "    \n",
    "    ins_id = subprocess.getoutput(\"aws ec2 describe-instances --filters Name=tag:Name,Values=testos1 --query Reservations[*].Instances[*].[InstanceId] --output text\")\n",
    "    vol_id = subprocess.getoutput(\"aws ec2 describe-volumes  --filters Name=tag:Name,Values=testos1* --query Volumes[*].[VolumeId] --output text\")\n",
    "    time.sleep(30)\n",
    "    c = os.system(\"aws ec2 attach-volume --instance-id {} --volume-id {} --device /dev/sdf\".format(ins_id,vol_id))\n",
    "    if c == 0:\n",
    "        print(\"Success : Volume ATTACHED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYjDyUD5Gq44"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Face Recognition – Unlock Your Computer With Your Face.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
